<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><![endif]-->
<title>Matan's Homepage</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--
<meta name="description" content="Haggai's web page" />
<meta name="author" content="tamarillo" />
-->
<!-- favicons -->
<!-- <link rel="shortcut icon" href="images/templatemo_favicon.ico"> -->
<!-- bootstrap core CSS -->
<link href="css/bootstrap.min.css" rel="stylesheet" />
<!-- fancybox CSS -->
<link href="css/jquery.lightbox.css" rel="stylesheet" />
<!-- flex slider CSS -->
<link href="css/flexslider.css" rel="stylesheet" />
<!-- custom styles for this template -->
<link href="css/templatemo_style.css" rel="stylesheet" />
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
<![endif]-->
</head>
<body>
<header>
    <div class="container">
        <div class="row">

            <div class="col-md-3 hidden-xs"></div>
            <div class="col-xs-3 col-xs-offset-20 visible-xs">
                <a href="#" id="mobile_menu"><span class="glyphicon glyphicon-align-justify"></span></a>
            </div>
            <div class="col-xs-24 visible-xs" id="mobile_menu_list">
                <ul>
					<li><a href="#templatemo_about">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                    <li><a href="/blog/" onclick="location.replace('https://matanatz.github.io/blog'),'_top'">Blog</a></li>
                </ul>
            </div>
            <div class="col-md-16 col-sm-18 hidden-xs" id="templatemo-nav-bar">
                <ul class="nav navbar-right">
					<li><a href="#templatemo_about">About</a></li>
                    <!-- <li><a href="#templatemo_slideshow">Slideshow</a></li> -->
                    <li><a href="#templatemo_publications">Publications</a></li>
                </ul>
            </div>
        </div>
    </div>
</header><!-- end of templatemo_header -->

<section id="templatemo_about">
    <div class="container">
        <div class="row">
            <div class="col-md-2"></div>
            <div id="my_photo" class="col-md-4 col-sm-7 col-xs-24">
                <img src="images/matan.jpg" alt="image 1"/>
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Matan Atzmon</h2>
				<p>
                I am a Ph.D. student at the Department of Computer Science and Applied Mathematics at the Weizmann Institute of Science under the supervision of <a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Prof. Yaron Lipman</a>.
                    <br>
                My main research interest is in applying deep learning to irregular domains (e.g., point clouds, and surfaces).
                <br>

                
		<br>

                </p>
				<p>
                <b>Email:</b> matan(dot)atzmon(at)weizmann(dot)ac(dot)il, <a href="https://scholar.google.com/citations?user=BXNft08AAAAJ&hl=en">Google scholar page</a>, <a href="https://github.com/matanatz">GitHub page</a><br>

				</p>


            </div>
        </div><!-- end of row -->
    </div>
</section><!-- end of templatemo_about -->




<section id="templatemo_publications">
    <div class="container">
		<hr>
        <div class="row">
            <h1>Publications</h1>
        </div>


      </div>



   <!--udr -->
      <div class="row" id="templatemo_publications_LargeScaleBD">
          <div class="col-md-1"></div>
          <div class="col-md-5 col-sm-7 col-xs-24">
              <img src="projects/udr/udr.png"  alt="">
          </div>
          <div class="col-md-1"></div>
          <div class="col-md-16">
              <h2>Universal Differentiable Renderer for Implicit Neural Representations</h2>
              <p>
                Lior Yariv, Matan Atzmon, Yaron Lipman<br>
              <i>Technical report</i> <br>
              </p>
              <a class="btn btn-default abstract" ptitle="The goal of this work is to learn implicit 3D shape representation with 2D supervision (\ie, a collection of images).  To that end we introduce the Universal Differentiable Renderer (UDR) a neural network architecture that can provably approximate reflected light from an implicit neural representation of a 3D surface, under a wide set of reflectance properties and lighting conditions. Experimenting with the task of multiview 3D reconstruction, we find our model to improve upon the baselines in the accuracy of the reconstructed 3D geometry and rendering from unseen viewing directions."> Abstract</a>
              <a href="https://arxiv.org/abs/2003.09852" class="btn btn-default">Arxiv </a>
          </div>
  </div><!-- end of row -->





        </div>
        <!--sal__ -->
              <div class="row" id="templatemo_publications_LargeScaleBD">
                  <div class="col-md-1"></div>
                  <div class="col-md-5 col-sm-7 col-xs-24">
                      <img src="projects/sal++/cars.png"  alt="">
                  </div>
                  <div class="col-md-1"></div>
                  <div class="col-md-16">
                      <h2>SAL++: Sign Agnostic Learning with Derivatives</h2>
                      <p>
                      Matan Atzmon and Yaron Lipman<br>
                      <i> Technical report </i> <br>
                      </p>
                      <a class="btn btn-default abstract" ptitle="Learning 3D geometry directly from raw data, such as point clouds, triangle soups, or un-oriented meshes is still a challenging task that feeds many downstream computer vision and graphics applications. In this paper, we introduce SAL++: a method for learning implicit neural representations of shapes directly from such raw data. We build upon the recent sign agnostic learning (SAL) approach and generalize it to include derivative data in a sign agnostic manner. In more detail, given the unsigned distance function to the input raw data, we suggest a novel sign agnostic regression loss, incorporating both pointwise values and gradients of the unsigned distance function. Optimizing this loss leads to a signed implicit function solution, the zero level set of which is a high quality, valid manifold approximation to the input 3D data. We demonstrate the efficacy of SAL++ shape space learning from two challenging datasets: ShapeNet that contains inconsistent orientation and non-manifold meshes, and D-Faust that contains raw 3D scans (triangle soups). On both these datasets, we present state-of-the-art results."> Abstract</a>
                      <a href="https://arxiv.org/abs/2006.05400" class="btn btn-default">Arxiv </a>
                  </div>
          </div><!-- end of row -->

        </div>
        
        
        
     <!--igr -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/igr/igr.png"  alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Implicit Geometric Regularization for Learning Shapes</h2>
                <p>
                Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman<br>
                <i> International Conference on Machine Learning (ICML) 2020 </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Representing shapes as level sets of neural networks has been recently proved to be useful for different shape analysis and reconstruction tasks. So far, such representations were computed using either: (i) pre-computed implicit shape representations; or (ii) loss functions explicitly defined over the neural level sets. In this paper we offer a new paradigm for computing high fidelity implicit neural representations directly from raw data (ie, point clouds, with or without normal information). We observe that a rather simple loss function, encouraging the neural network to vanish on the input point cloud and to have a unit norm gradient, possesses an implicit geometric regularization property that favors smooth and natural zero level set surfaces, avoiding bad zero-loss solutions. We provide a theoretical analysis of this property for the linear case, and show that, in practice, our method leads to state of the art implicit neural representations with higher level-of-details and fidelity compared to previous methods."> Abstract</a>
                <a href="https://arxiv.org/abs/2002.10099" class="btn btn-default">Arxiv </a>
            </div>
    </div><!-- end of row -->

  </div>
   

 <!--sal -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/sal/sal.gif" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>SAL: Sign Agnostic Learning of Shapes from Raw Data	</h2>
                <p>
                Matan Atzmon and Yaron Lipman<br>
                <i> Computer Vision and Pattern Recognition (CVPR) 2020, oral presentation </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="Recently, neural networks have been used as implicit representations for surface reconstruction, modelling, learning, and generation.  So far, training neural networks to be implicit representations of surfaces required training data sampled from a ground-truth signed implicit functions such as signed distance or occupancy functions, which are notoriously hard to compute. In this paper we introduce Sign Agnostic Learning (SAL), a deep learning approach for learning implicit shape representations directly from raw, unsigned geometric data, such as point clouds and triangle soups. We have tested SAL on the challenging problem of surface reconstruction from an un-oriented point cloud, as well as end-to-end human shape space learning directly from raw scans dataset, and achieved state of the art reconstructions compared to current approaches. We believe SAL opens the door to many geometric deep learning applications with real-world data, alleviating the usual painstaking, often manual pre-process. "> Abstract</a>
                <a href="https://arxiv.org/abs/1911.10414" class="btn btn-default">Arxiv </a>
                <a href="https://github.com/matanatz/SAL" class="btn btn-default">  Code </a>
		<a href="https://youtu.be/vx3jl72qqO0" class="btn btn-default">  Video </a>




            </div>
        </div><!-- end of row -->

     <!--levelsets -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/level_sets/2019_neural_levelsets.png" alt="">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Controlling Neural Level Sets	</h2>
                <p>
                Matan Atzmon, Niv Haim, Lior Yariv, Ofer Israelov, Haggai Maron, Yaron Lipman <br>
                <i> 33rd Annual Conference on Neural Information Processing Systems (NeurIPS 2019) </i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="The level sets of neural networks represent fundamental properties such as decision boundaries of classifiers and are used to model non-linear manifold data such as curves and surfaces. Thus, methods for controlling the neural level sets could find many applications in machine learning. In this paper we present a simple and scalable approach to directly control level sets of a deep neural network. Our method consists of two parts: (i) sampling of the neural level sets, and (ii) relating the samples’ positions to the network parameters. The latter is achieved by a sample network that is constructed by adding a single fixed linear layer to the original network. In turn, the sample network can be used to incorporate the level set samples into a loss function of interest. We have tested our method on three different learning tasks:  raining networks robust to adversarial attacks, improving generalization to unseen data, and curve and surface reconstruction from point clouds. Notably, we increase robust accuracy to the level of standard classification accuracy in off-the-shelf networks, improving it by 2% in MNIST and 27% in CIFAR10 compared to state-of-the-art methods. For surface reconstruction, we produce high fidelity surfaces directly from raw 3D point clouds."> Abstract</a>
                <a href="https://arxiv.org/abs/1905.11911" class="btn btn-default">Arxiv </a>
                <a href="https://github.com/matanatz/ControllingNeuralLevelsets" class="btn btn-default">Code </a>
                <a href="https://github.com/matanatz/ControllingNeuralLevelsets/blob/master/Controlling_Neural_Level_Sets_Poster.pdf" class="btn btn-default">Poster </a>
            </div>
        </div><!-- end of row -->





        <!--PCNN -->
        <div class="row" id="templatemo_publications_LargeScaleBD">
            <div class="col-md-1"></div>
            <div class="col-md-5 col-sm-7 col-xs-24">
                <img src="projects/PCNN/rep.png" alt="image 1">
            </div>
            <div class="col-md-1"></div>
            <div class="col-md-16">
                <h2>Point Convolutional Neural Networks by Extension Operators</h2>
                <p>
                Matan Atzmon*, Haggai Maron* and Yaron Lipman (*equal contribution)<br>
                <i>ACM SIGGRAPH 2018</i> <br>
                </p>
                <a class="btn btn-default abstract" ptitle="This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction, mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism. The point cloud convolution is computationally efficient, invariant to the order of points in the point cloud, robust to different samplings and varying densities, and translation invariant, that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting. Evaluation of PCNN on three central point cloud learning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals"> Abstract</a>
                <a href="https://arxiv.org/abs/1803.10091" class="btn btn-default">  Arxiv </a>
                <a href="https://github.com/matanatz/pcnn" class="btn btn-default">GitHub</a>
                <a href="projects/PCNN/pointConv_sigraph_final_pdf.pdf" class="btn btn-default">Slides</a>
		<a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3197517.3201301&file=a71-atzmon.mp4" class="btn btn-default">Video</a>

        </div>
        


</section><!-- end of templatemo_publications -->

<br>
<br>

<!--<script src="https://maps.googleapis.com/maps/api/js?v=3.exp&amp;sensor=false"></script> -->
<script src="js/jquery.min.js"></script>
<script src="js/jquery.scrollto.min.js"></script>
<script src="js/jquery.easing.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.lightbox.min.js"></script>
<script src="js/jquery.flexslider.js"></script>
<script src="js/jquery.singlePageNav.min.js"></script>
<script src="js/templatemo_script.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','../../www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52088992-1', 'weizmann.ac.il');
  ga('require', 'linkid', 'linkid.html');
  ga('send', 'pageview');
</script>
</body>

<!-- Mirrored from www.wisdom.weizmann.ac.il/~shaharko/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 06 Apr 2016 11:56:56 GMT -->
</html>
